load("~/OBIWAN/dfsim.Rdata")
View(dfsim)
summary(lm(alpha ~ alphaO, data=dfsim))$r.squared
dfsim$alphaO
lm(alpha ~ alphaO, data=dfsim)
summary(lm(alpha ~ alphaO, data=dfsim))$r.squared
dfsim$alpha
dfsim$alpha = as.numeric(as.character(dfsim$alpha))
dfsim$alphaO
dfsim$alpha
summary(lm(alpha ~ alphaO, data=dfsim))$r.squared
lm(alpha ~ alphaO, data=dfsim)
test1 = summary(lm(alpha ~ alphaO, data=dfsim))
test1$r.squared
test1
BayesFactor::lmBF(alpha ~ alphaO, data=dfsim)
tesBF1 = BayesFactor::lmBF(alpha ~ alphaO, data=dfsim);
tesBF1
tesBF1[1]
solu = sim(simDATA , s)
## R code for FOR PROBA LEARNING TASK OBIWAN
# last modified on April 2020 by David MUNOZ TORD
# PRELIMINARY STUFF ----------------------------------------
#if there is any bug please run this line below once ant then rerun the script
#invisible(lapply(paste0('package:', names(sessionInfo()$otherPkgs)), detach, character.only=TRUE, unload=TRUE))
#load packages
if(!require(pacman)) {
install.packages("pacman")
library(pacman)
}
pacman::p_load(tidyverse, plyr,dplyr,readr,rlist, ggpubr, NlcOptim,pracma, here, foreach, parallel, doSNOW, future, corrplot, RColorBrewer)
# SETUP ------------------------------------------------------------------
task = 'PBlearning'
# Set working directory #change here if the switchdrive is not on your home folder
analysis_path <- file.path('~/Desktop/SwitchDrive/OBIWAN/PROBA_LEARNING/Analysis')
figures_path  <- file.path('~/Desktop/SwitchDrive/OBIWAN/PROBA_LEARNING/Figures')
setwd(analysis_path)
cores=parallel::detectCores()
#cl <- future::makeCluster(cores[1]/2, outfile="") #for my machine
cl <- parallel::makeCluster(cores[1]/2, outfile="") # for centOS cluster
registerDoSNOW(cl)
# simulate behavior -------------------------------------------------------
set.seed(666)
source('~/Desktop/SwitchDrive/OBIWAN/PROBA_LEARNING/Analysis/PST_dualQ_learning.R', echo=TRUE)
# create data structure ----------------------------------------------
s = 100 #number of subjects to simulate
simDATA = c();
paramA = rand(s,1);  #rbeta(1, shape1=5, shape2=1.5) 1-rbeta(1, shape1=5, shape2=1.5)
paramB = rand(s,1);  #rbeta(1, shape1=5, shape2=1.5) 1-rbeta(1, shape1=5, shape2=1.5)
paramC = rgamma(s, shape =4, scale =0.5); #rgamma(1, shape =4, scale =0.5)
create <- function(i){
alphaG = paramA[i]
alphaL = paramB[i]
beta = paramC[i]
ID = rep(i, each=180)
type = sample(rep(c(12, 34, 56), each=60))
data = cbind(ID, type); data = as_tibble(data)
d = simulatedualPST(alphaG, alphaL, beta, data)
return(d)
}
pb <- txtProgressBar(min = 1, max = s, style = 3)
simDATA <- foreach(i = 1:s, .combine = 'rbind', .packages = c("pracma", "tidyverse")) %dopar% {
sol = create(i)
setTxtProgressBar(pb, i)
return(sol)
}
# d = subset(simDATA, ID%in%1:10)
# d$trial = rep(1:180, 10)
# data_long <- gather(d, option, ev, ev1:ev6, factor_key=TRUE)
# data_long$option <- factor(data_long$option, levels = c("ev1", "ev3", "ev5", "ev2", "ev4", "ev6"))
#
# data_long %>%
#   ggplot(aes(x = trial, y = ev, color =as.factor(ID))) +
#   geom_line(size=0.5) +
#   #geom_line(aes(y=pe), color ='red',size=0.5) +
#   ylim(0,1) +
#   facet_wrap("option")
# Re-estimate model's parameters  ----------------------------------------------------------
source('~/Desktop/SwitchDrive/OBIWAN/PROBA_LEARNING/Analysis/PST_Q_learning.R', echo=TRUE)
set.seed(666); Nrep = 100; k = 2 # number of free parameteres
subj = unique(simDATA$ID)
alpha = c(); beta = c(); nll= c(); ID = c(); group = c(); trials = c(); dft = c()
LB = c(0, 0, 0); UB = c(1, 1, 10) # parameters lower and upper bounds
sim <- function(simDATA, s){
data = subset(simDATA, ID == s)
param_rep = c(); nll_rep = c()
for (i in  1:Nrep) {
x0 = c(rand(),rand(), rgamma(1, shape =4, scale =0.5)); #different parameter initial values to avoid local minima
f = fmincon(x0=x0,fn=PST_q_dual, data = data, lb = LB, ub = UB) #optimize
param_rep = rbind(param_rep, f$par); nll_rep = rbind(nll_rep, f$value)
}
pos = which.min(nll_rep)
dft$alphaG = param_rep[pos,1]; dft$alphaL = param_rep[pos,2]; dft$beta = param_rep[pos,3]; dft$nll = nll_rep[pos]; dft$ID = s;  dft$trials =length(data$ID)
return(dft)
}
s
solu = sim(simDATA , s)
solu
tryCatch(log("ABC"),
error = function(e)
print("You can't calculate the log of a character"))
tryCatch(log(1),
error = function(e)
print("You can't calculate the log of a character"))
sol = tryCatch(log("ABC"),
error = function(e)
print("You can't calculate the log of a character"))
solu
View(solu)
sol = tryCatch(log("ABC"),
error = function(e)
list(alphaG = 0, alphaL = 0, beta = 0, nll= 0, ID=s, trials=180)
list(alphaG = 0, alphaL = 0, beta = 0, nll= 0, ID=s, trials=180))
return(list(alphaG = 0, alphaL = 0, beta = 0, nll= 0, ID=s, trials=180)))
sol = tryCatch(log("ABC"),
error = function(e) return(list(alphaG = 0, alphaL = 0, beta = 0, nll= 0, ID=s, trials=180)))
sol;
sol
dfsim = subset(dfsim, beta != 10 & beta != 0)
dfsim
max(dfsim$beta)
max(as.numeric(dfsim$beta))
max(as.numeric(as.character(dfsim$beta)))
1e-10
1e-1
1e-10
1e-100
9e-4
9e-2
9e-3
corrplot(cor(dfsim[c(1:3)]), type="upper", order="hclust",
col=brewer.pal(n=8, name="PuOr"))
dfsim[c(1:3)]
